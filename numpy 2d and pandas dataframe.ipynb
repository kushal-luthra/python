{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "[[2328 2539]\n",
      " [6461 2691]]\n",
      "[1478 3877 3674 2328 2539]\n"
     ]
    }
   ],
   "source": [
    "#case 1:\n",
    "import numpy as np\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements\n",
    "if 1:\n",
    "    print(ridership[1, 3])\n",
    "    print(ridership[1:3, 3:5])\n",
    "    print(ridership[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1478 3877 3676 2333 2539]\n",
      "[   0 5355 5701 4952 6410 5509  324    2 5223 5385]\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on rows or columns\n",
    "if 1:\n",
    "    print(ridership[0, :] + ridership[1, :])\n",
    "    print(ridership[:, 0] + ridership[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4]\n",
      " [ 6  7  8]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on entire arrays\n",
    "if 1:\n",
    "    a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 5 0]\n",
      "5\n",
      "3\n",
      "2342.6\n"
     ]
    }
   ],
   "source": [
    "print(ridership[0,:])\n",
    "print(ridership[0,:].max())\n",
    "print(ridership[0,:].argmax())\n",
    "print(ridership.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2342.5999999999999, 3239.9000000000001)\n"
     ]
    }
   ],
   "source": [
    "#case study 2: \n",
    "'''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.'''\n",
    "    \n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    #overall_mean = None # Replace this with your code\n",
    "    #mean_for_max = None # Replace this with your code\n",
    "    \n",
    "    #station with max ridership on 1st day\n",
    "    station_1_day_max=ridership[0,:].argmax()\n",
    "    \n",
    "    mean_for_max=ridership[:,station_1_day_max].mean()\n",
    "    overall_mean=ridership.mean()\n",
    "    \n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "print(mean_riders_for_max_station(ridership))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#case study 2: operations along axis\n",
    "'''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "'''\n",
    "def min_and_max_riders_per_day(ridership):\n",
    "    #mean ridership per day for each subway station\n",
    "    ridership.mean(axis=0)\n",
    "    \n",
    "    \n",
    "    max_daily_ridership = ridership.mean(axis=0).max()     # Replace this with your code\n",
    "    min_daily_ridership = ridership.mean(axis=0).min()     # Replace this with your code\n",
    "    \n",
    "    #calculating mean ridership for each station\n",
    "    \n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R003</th>\n",
       "      <th>R004</th>\n",
       "      <th>R005</th>\n",
       "      <th>R006</th>\n",
       "      <th>R007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05-01-11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-02-11</th>\n",
       "      <td>1478</td>\n",
       "      <td>3877</td>\n",
       "      <td>3674</td>\n",
       "      <td>2328</td>\n",
       "      <td>2539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-03-11</th>\n",
       "      <td>1613</td>\n",
       "      <td>4088</td>\n",
       "      <td>3991</td>\n",
       "      <td>6461</td>\n",
       "      <td>2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-04-11</th>\n",
       "      <td>1560</td>\n",
       "      <td>3392</td>\n",
       "      <td>3826</td>\n",
       "      <td>4787</td>\n",
       "      <td>2613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-05-11</th>\n",
       "      <td>1608</td>\n",
       "      <td>4802</td>\n",
       "      <td>3932</td>\n",
       "      <td>4477</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-06-11</th>\n",
       "      <td>1576</td>\n",
       "      <td>3933</td>\n",
       "      <td>3909</td>\n",
       "      <td>4979</td>\n",
       "      <td>2685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-07-11</th>\n",
       "      <td>95</td>\n",
       "      <td>229</td>\n",
       "      <td>255</td>\n",
       "      <td>496</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-08-11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-09-11</th>\n",
       "      <td>1438</td>\n",
       "      <td>3785</td>\n",
       "      <td>3589</td>\n",
       "      <td>4174</td>\n",
       "      <td>2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-10-11</th>\n",
       "      <td>1342</td>\n",
       "      <td>4043</td>\n",
       "      <td>4009</td>\n",
       "      <td>4665</td>\n",
       "      <td>3033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          R003  R004  R005  R006  R007\n",
       "05-01-11     0     0     2     5     0\n",
       "05-02-11  1478  3877  3674  2328  2539\n",
       "05-03-11  1613  4088  3991  6461  2691\n",
       "05-04-11  1560  3392  3826  4787  2613\n",
       "05-05-11  1608  4802  3932  4477  2705\n",
       "05-06-11  1576  3933  3909  4979  2685\n",
       "05-07-11    95   229   255   496   201\n",
       "05-08-11     2     0     1    27     0\n",
       "05-09-11  1438  3785  3589  4174  2215\n",
       "05-10-11  1342  4043  4009  4665  3033"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "ridership_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R003    0\n",
      "R004    0\n",
      "R005    2\n",
      "R006    5\n",
      "R007    0\n",
      "Name: 05-01-11, dtype: int64 \n",
      "\n",
      "2328 \n",
      "\n",
      "R003    1608\n",
      "R004    4802\n",
      "R005    3932\n",
      "R006    4477\n",
      "R007    2705\n",
      "Name: 05-05-11, dtype: int64 \n",
      "\n",
      "1608 \n",
      "\n",
      "05-01-11       0\n",
      "05-02-11    1478\n",
      "05-03-11    1613\n",
      "05-04-11    1560\n",
      "05-05-11    1608\n",
      "05-06-11    1576\n",
      "05-07-11      95\n",
      "05-08-11       2\n",
      "05-09-11    1438\n",
      "05-10-11    1342\n",
      "Name: R003, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#diff ways of accessing elements\n",
    "# iloc() helps access by POSITION\n",
    "print(ridership_df.iloc[0],\"\\n\") # accessing elements of SINGLE ROW\n",
    "print(ridership_df.iloc[1, 3],\"\\n\") #accessing element at Single Posn\n",
    "\n",
    "# loc() helps access by INDEX: \n",
    "print(ridership_df.loc['05-05-11'],\"\\n\") #accessing elements of SINGLE ROW\n",
    "print(ridership_df.loc['05-05-11','R003'],\"\\n\") #accessing element at Single Posn\n",
    "\n",
    "\n",
    "#accessing by column name\n",
    "print(ridership_df['R003'],\"\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R003  R004  R005  R006  R007\n",
      "05-02-11  1478  3877  3674  2328  2539\n",
      "05-03-11  1613  4088  3991  6461  2691\n",
      "05-04-11  1560  3392  3826  4787  2613 \n",
      "\n",
      "          R003  R005\n",
      "05-01-11     0     2\n",
      "05-02-11  1478  3674\n",
      "05-03-11  1613  3991\n",
      "05-04-11  1560  3826\n",
      "05-05-11  1608  3932\n",
      "05-06-11  1576  3909\n",
      "05-07-11    95   255\n",
      "05-08-11     2     1\n",
      "05-09-11  1438  3589\n",
      "05-10-11  1342  4009\n"
     ]
    }
   ],
   "source": [
    "#accessing multiple rows\n",
    "print(ridership_df.iloc[1:4,],\"\\n\")\n",
    "\n",
    "# Accessing multiple columns\n",
    "print(ridership_df[['R003', 'R005']]) #notice the double brackets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  0  3\n",
      "1  1  4\n",
      "2  2  5 \n",
      "\n",
      "   A  B  C\n",
      "0  0  1  2\n",
      "1  3  4  5\n"
     ]
    }
   ],
   "source": [
    "# You can create a DataFrame out of a dictionary mapping column names to values\n",
    "df_1 = pd.DataFrame({'A': [0, 1, 2], #dictionary key-value pair\n",
    "                     'B': [3, 4, 5]})\n",
    "print(df_1,\"\\n\")\n",
    "\n",
    "df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], #2d array as rows\n",
    "                    columns=['A', 'B', 'C'])\n",
    "print(df_2)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  0  3\n",
      "1  1  4\n",
      "2  2  5 \n",
      "\n",
      "A     3\n",
      "B    12\n",
      "dtype: int64 \n",
      "\n",
      "0    3\n",
      "1    5\n",
      "2    7\n",
      "dtype: int64 \n",
      "\n",
      "sum of all values in df  15\n"
     ]
    }
   ],
   "source": [
    "#pandas axis\n",
    "df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "print(df,\"\\n\")\n",
    "print(df.sum(),\"\\n\") #by default sum is along columns\n",
    "print(df.sum(axis=1),\"\\n\") #find SUM across ROWS\n",
    "\n",
    "#df.values gives output as numpy array, on which we can apply numpy functions to find sum of ALL values in dataframe\n",
    "#values() gives only value of dataframe and not column name or index name\n",
    "print(\"sum of all values in df= \", df.values.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2342.6000000000004, 3239.9)\n"
     ]
    }
   ],
   "source": [
    "#case study\n",
    "'''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "'''\n",
    "    \n",
    "def mean_riders_for_max_station(ridership_df):\n",
    "        \n",
    "    #station with ridership which is max on day 1\n",
    "    station=ridership_df.iloc[0].argmax()\n",
    "    mean_for_max = ridership_df.loc[:,station].mean() \n",
    "    \n",
    "    #to calculate overall_mean: way 1\n",
    "    x=ridership_df.iloc[:,:].mean() #this will give overall mean at column level\n",
    "    overall_mean=x.mean() #now find mean of all columns\n",
    "    \n",
    "    #to calculate overall_mean: way 2: doing above in single line of code\n",
    "    #overall_mean=ridership_df.loc[:,ridership_df.iloc[0].argmax()].mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "print(mean_riders_for_max_station(ridership_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3239.9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(ridership_df.iloc[0])\n",
    "#print(ridership_df.iloc[0].argmax())\n",
    "ridership_df.loc[:,ridership_df.iloc[0].argmax()].mean()\n",
    "#ridership_df.iloc[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#case study: writing our own pearson correlation r function\n",
    "import pandas as pd\n",
    "\n",
    "filename = '/datasets/ud170/subway/nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    #step1: standardize all values\n",
    "    #note: ddof=0 means we are taking uncorrected standard variable. This is how pearson's r is caculated\n",
    "    p=(x.values-x.values.mean())/x.values.std(ddof=0)\n",
    "    q=(y.values-y.values.mean())/y.values.std(ddof=0)\n",
    "    \n",
    "    \n",
    "    r=p*q\n",
    "    \n",
    "    #print p\n",
    "    #print q\n",
    "    #print r\n",
    "    return r.mean()\n",
    "\n",
    "entries = subway_df['ENTRIESn_hourly']\n",
    "cum_entries = subway_df['ENTRIESn']\n",
    "rain = subway_df['meanprecipi']\n",
    "temp = subway_df['meantempi']\n",
    "\n",
    "print correlation(entries, rain)\n",
    "print correlation(entries, temp)\n",
    "print correlation(rain, temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding DataFrames with the column names\n",
      "     a   b   c\n",
      "0  11  44  77\n",
      "1  22  55  88\n",
      "2  33  66  99 \n",
      "\n",
      "Adding DataFrames with overlapping column names\n",
      "     a   b   c   d\n",
      "0 NaN  74  47 NaN\n",
      "1 NaN  85  58 NaN\n",
      "2 NaN  96  69 NaN \n",
      "\n",
      "Adding DataFrames with overlapping row indexes\n",
      "          a     b     c\n",
      "row1   NaN   NaN   NaN\n",
      "row2  32.0  65.0  98.0\n",
      "row3  23.0  56.0  89.0\n",
      "row4   NaN   NaN   NaN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examples of vectorized operations on DataFrames:\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "print(\"Adding DataFrames with the column names\\n\",df1 + df2,\"\\n\")\n",
    "    \n",
    "# Adding DataFrames with overlapping column names \n",
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "print(\"Adding DataFrames with overlapping column names\\n\",df1 + df2,\"\\n\")\n",
    "\n",
    "# Adding DataFrames with overlapping row indexes\n",
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                   index=['row1', 'row2', 'row3'])\n",
    "df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                   index=['row4', 'row3', 'row2'])\n",
    "print(\"Adding DataFrames with overlapping row indexes\\n\",df1 + df2,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns = 2\n",
      "ENTRIESn = 0\n",
      "entries in columns =   10\n",
      "EXITSn = 1\n",
      "entries in columns =   10\n",
      "   EXITSn  ENTRIESn\n",
      "0     0.0       0.0\n",
      "1    23.0       8.0\n",
      "2    18.0      18.0\n",
      "3    71.0      54.0\n",
      "4   170.0      44.0\n",
      "5   214.0      42.0\n",
      "6    87.0      11.0\n",
      "7    10.0       3.0\n",
      "8    36.0      89.0\n",
      "9   153.0     333.0\n"
     ]
    }
   ],
   "source": [
    "# --- Quiz ---\n",
    "# Cumulative entries and exits for one station for a few hours.\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "'''\n",
    "Fill in this function to take a DataFrame with cumulative entries\n",
    "and exits (entries in the first column, exits in the second) and\n",
    "return a DataFrame with hourly entries and exits (entries in the\n",
    "first column, exits in the second).\n",
    "'''\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    p=entries_and_exits.values\n",
    "        \n",
    "    from pandasql import sqldf\n",
    "    col_series=pd.Series(entries_and_exits.columns)\n",
    "    col_count=sqldf(\"select count(*) from col_series\")\n",
    "\n",
    "    num_cols=int(col_count.iloc[0])\n",
    "    print(\"number of columns =\",num_cols)\n",
    "\n",
    "    for i in range(num_cols):\n",
    "        print(entries_and_exits.columns[i],\"=\",i)\n",
    "\n",
    "        entries_in_col=np.size(entries_and_exits.values[:,i])\n",
    "        print(\"entries in columns =  \",entries_in_col)\n",
    "\n",
    "        if i==0:\n",
    "            new_array=np.zeros(shape=(num_cols,entries_in_col))\n",
    "        my_array=entries_and_exits.values[:,i]\n",
    "        #new_array=entries_and_exits.values[:,i]\n",
    "\n",
    "\n",
    "        for j in range(entries_in_col):\n",
    "            if j!=0:\n",
    "                #print(\"hi\")\n",
    "                x=my_array[j]\n",
    "                y=my_array[j-1]\n",
    "                #new_array[j]=my_array[j]-my_array[j-1]\n",
    "                new_array[i,j]=x-y\n",
    "                x=my_array[j]\n",
    "                y=my_array[j-1]\n",
    "                #print(j,\" \",x,\" \",y,\"\",x-y,\"\\n\")\n",
    "                #print(my_array[j],\" \",new_array[i,j],\"\\n\")\n",
    "            else:\n",
    "                new_array[i,j]=0\n",
    "\n",
    "            #print(my_array,\"\\n\")\n",
    "            #print(new_array)\n",
    "    my_df=pd.DataFrame(new_array.transpose())\n",
    "    #my_df.rename(columns={0:'ENTRIESn',1:'EXITSn'})   \n",
    "    my_df.columns={'ENTRIESn','EXITSn'}\n",
    "    return my_df\n",
    "\n",
    "print(get_hourly_entries_and_exits(entries_and_exits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn  EXITSn\n",
      "0       0.0     0.0\n",
      "1      23.0     8.0\n",
      "2      18.0    18.0\n",
      "3      71.0    54.0\n",
      "4     170.0    44.0\n",
      "5     214.0    42.0\n",
      "6      87.0    11.0\n",
      "7      10.0     3.0\n",
      "8      36.0    89.0\n",
      "9     153.0   333.0\n"
     ]
    }
   ],
   "source": [
    "#alternate way to do above code is using shift() which moves values down by number specified in parameter to shift\n",
    "def get_hourly_entries_and_exits_2(entries_and_exits):\n",
    "    entries_and_exits2=entries_and_exits.shift(1)\n",
    "    my_df=entries_and_exits-entries_and_exits2\n",
    "    z=my_df.fillna(0) #drop missing values across axis=0 i.e. rows\n",
    "    \n",
    "    return z\n",
    "print(get_hourly_entries_and_exits_2(entries_and_exits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(*)    2\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pandasql import sqldf\n",
    "col_series=pd.Series(entries_and_exits.columns)\n",
    "col_count=sqldf(\"select count(*) from col_series\")\n",
    "print(col_count.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.size(entries_and_exits.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=entries_and_exits.values\n",
    "from pandasql import sqldf\n",
    "col_series=pd.Series(entries_and_exits.columns)\n",
    "col_count=sqldf(\"select count(*) from col_series\")\n",
    "\n",
    "num_cols=int(col_count.iloc[0])\n",
    "print(\"number of columns =\",num_cols)\n",
    "\n",
    "for i in range(num_cols):\n",
    "    print(entries_and_exits.columns[i],\"=\",i)\n",
    "    \n",
    "    entries_in_col=np.size(entries_and_exits.values[:,i])\n",
    "    print(\"entries in columns =  \",entries_in_col)\n",
    "    \n",
    "    if i==0:\n",
    "        new_array=np.zeros(shape=(num_cols,entries_in_col))\n",
    "    my_array=entries_and_exits.values[:,i]\n",
    "    #new_array=entries_and_exits.values[:,i]\n",
    "    \n",
    "    \n",
    "    for j in range(entries_in_col):\n",
    "        if j!=0:\n",
    "            #print(\"hi\")\n",
    "            x=my_array[j]\n",
    "            y=my_array[j-1]\n",
    "            #new_array[j]=my_array[j]-my_array[j-1]\n",
    "            new_array[i,j]=x-y\n",
    "        x=my_array[j]\n",
    "        y=my_array[j-1]\n",
    "        #print(j,\" \",x,\" \",y,\"\",x-y,\"\\n\")\n",
    "        #print(my_array[j],\" \",new_array[i,j],\"\\n\")\n",
    "    \n",
    "    \n",
    "    #print(my_array,\"\\n\")\n",
    "    print(new_array)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#new case study: use of applymap()\n",
    "#applymap() - for applying user defined function on each element of DATAFRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         exam1  exam2\n",
      "Andre       43     24\n",
      "Barry       81     63\n",
      "Chris       78     56\n",
      "Dan         75     56\n",
      "Emilio      89     67\n",
      "Fred        70     51\n",
      "Greta       91     79\n",
      "Humbert     65     46\n",
      "Ivan        98     72\n",
      "James       87     60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        exam1 exam2\n",
       "Andre       E     E\n",
       "Barry       B     D\n",
       "Chris       C     E\n",
       "Dan         C     E\n",
       "Emilio      B     D\n",
       "Fred        C     E\n",
       "Greta       A     C\n",
       "Humbert     D     E\n",
       "Ivan        A     C\n",
       "James       B     D"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DataFrame applymap()\n",
    "if 0:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "    \n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print(df.applymap(add_one))\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "print(grades_df)\n",
    "\n",
    "\n",
    "'''\n",
    "Fill in this function to convert the given DataFrame of numerical\n",
    "grades to letter grades. Return a new DataFrame with the converted\n",
    "grade.\n",
    "\n",
    "The conversion rule is:\n",
    "    90-100 -> A\n",
    "    80-89  -> B\n",
    "    70-79  -> C\n",
    "    60-69  -> D\n",
    "    0-59   -> F\n",
    "'''\n",
    "\n",
    "def convert_grades(grades):\n",
    "    row_count,col_count=np.shape(grades.values)\n",
    "    my_df_array=grades.values\n",
    "    #new_df=grades.copy() \n",
    "    new_df=grades\n",
    "    for i in range(row_count):\n",
    "        #print(i)\n",
    "        for j in range(col_count):\n",
    "            if 90<=my_df_array[i,j]<=100:\n",
    "                new_df.iloc[i,j]='A'\n",
    "            elif 80<=my_df_array[i,j]<=89:\n",
    "                new_df.iloc[i,j]='B'\n",
    "            elif 70<=my_df_array[i,j]<=79:\n",
    "                new_df.iloc[i,j]='C'\n",
    "            elif 60<=my_df_array[i,j]<=69:\n",
    "                new_df.iloc[i,j]='D'\n",
    "            else:\n",
    "                new_df.iloc[i,j]='E'\n",
    "\n",
    "    #print(new_df)  \n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "#grades_df.applymap(convert_grades)\n",
    "grades_df=convert_grades(grades_df)\n",
    "\n",
    "grades_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         exam1  exam2\n",
      "Andre       43     24\n",
      "Barry       81     63\n",
      "Chris       78     56\n",
      "Dan         75     56\n",
      "Emilio      89     67\n",
      "Fred        70     51\n",
      "Greta       91     79\n",
      "Humbert     65     46\n",
      "Ivan        98     72\n",
      "James       87     60\n",
      "B\n",
      "        exam1 exam2\n",
      "Andre       E     E\n",
      "Barry       B     D\n",
      "Chris       C     E\n",
      "Dan         C     E\n",
      "Emilio      B     D\n",
      "Fred        C     E\n",
      "Greta       A     C\n",
      "Humbert     D     E\n",
      "Ivan        A     C\n",
      "James       B     D\n"
     ]
    }
   ],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "print(grades_df)\n",
    "\n",
    "#alternate way of doing above task: use applymap\n",
    "#step 1: create function to apply on single grade\n",
    "\n",
    "def convert_grade(grade):\n",
    "    if grade>=90:\n",
    "        return 'A'\n",
    "    elif grade>=80:\n",
    "        return 'B'\n",
    "    elif grade>=70:\n",
    "        return 'C'\n",
    "    elif grade>=60:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'E'\n",
    "\n",
    "#doing test run on single value\n",
    "print(convert_grade(80))\n",
    "\n",
    "#now applymap() is used to apply this function on each element of our dataframe\n",
    "def convert_grades2(grades):\n",
    "    return grades.applymap(convert_grade)\n",
    "\n",
    "print(convert_grades2(grades_df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "         exam1  exam2\n",
      "Andre       43     24\n",
      "Barry       81     63\n",
      "Chris       78     56\n",
      "Dan         75     56\n",
      "Emilio      89     67\n",
      "Fred        70     51\n",
      "Greta       91     79\n",
      "Humbert     65     46\n",
      "Ivan        98     72\n",
      "James       87     60\n",
      "        exam1 exam2\n",
      "Andre       E     E\n",
      "Barry       B     D\n",
      "Chris       C     E\n",
      "Dan         C     E\n",
      "Emilio      B     D\n",
      "Fred        C     E\n",
      "Greta       A     C\n",
      "Humbert     D     E\n",
      "Ivan        A     C\n",
      "James       B     D\n"
     ]
    }
   ],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "print(grades_df)\n",
    "\n",
    "#alternate way of doing above task: use applymap\n",
    "#step 1: create function to apply on single grade\n",
    "\n",
    "def convert_grade(grade):\n",
    "    if grade>=90:\n",
    "        return 'A'\n",
    "    elif grade>=80:\n",
    "        return 'B'\n",
    "    elif grade>=70:\n",
    "        return 'C'\n",
    "    elif grade>=60:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'E'\n",
    "\n",
    "#doing test run on single value\n",
    "#print(convert_grade(80))\n",
    "\n",
    "#now applymap() is used to apply this function on each element of our dataframe\n",
    "def convert_grades2(grades):\n",
    "    return grades.applymap(convert_grade)\n",
    "\n",
    "print(convert_grades2(grades_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply() – can be applied on dataframe such that –\n",
    "• It applies to each COLUMN, where each column is treated as individual series,  and returns a Series each time, so as to modify the DATAFRAME.\n",
    "• It can also be applied to each COLUMN of a dataframe such that it for each column, it returns a single object, and final returned value is a SERIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply() on 1 column of grades_df\n",
      " Andre      F\n",
      "Barry      B\n",
      "Chris      C\n",
      "Dan        C\n",
      "Emilio     B\n",
      "Fred       C\n",
      "Greta      A\n",
      "Humbert    D\n",
      "Ivan       A\n",
      "James      B\n",
      "Name: exam1, dtype: category\n",
      "Categories (5, object): [F < D < C < B < A]\n",
      "apply() on all column of grades_df\n",
      "         exam1 exam2\n",
      "Andre       F     F\n",
      "Barry       B     B\n",
      "Chris       C     C\n",
      "Dan         C     C\n",
      "Emilio      B     B\n",
      "Fred        C     C\n",
      "Greta       A     A\n",
      "Humbert     D     D\n",
      "Ivan        A     A\n",
      "James       B     B\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam1</th>\n",
       "      <th>exam2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>-2.196525</td>\n",
       "      <td>-2.186335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>0.208891</td>\n",
       "      <td>0.366571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>0.018990</td>\n",
       "      <td>-0.091643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dan</th>\n",
       "      <td>-0.170911</td>\n",
       "      <td>-0.091643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emilio</th>\n",
       "      <td>0.715295</td>\n",
       "      <td>0.628408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fred</th>\n",
       "      <td>-0.487413</td>\n",
       "      <td>-0.418938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greta</th>\n",
       "      <td>0.841896</td>\n",
       "      <td>1.413917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humbert</th>\n",
       "      <td>-0.803916</td>\n",
       "      <td>-0.746234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivan</th>\n",
       "      <td>1.284999</td>\n",
       "      <td>0.955703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>0.588694</td>\n",
       "      <td>0.170194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            exam1     exam2\n",
       "Andre   -2.196525 -2.186335\n",
       "Barry    0.208891  0.366571\n",
       "Chris    0.018990 -0.091643\n",
       "Dan     -0.170911 -0.091643\n",
       "Emilio   0.715295  0.628408\n",
       "Fred    -0.487413 -0.418938\n",
       "Greta    0.841896  1.413917\n",
       "Humbert -0.803916 -0.746234\n",
       "Ivan     1.284999  0.955703\n",
       "James    0.588694  0.170194"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case study: apply() function applies to each column of DATAFRAME. \n",
    "# In such case it treats each column as a Series.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply() and qcut() function\n",
    "def convert_grades_curve(exam_grades):\n",
    "    # Pandas has a bult-in function that will perform this calculation\n",
    "    # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "    # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "    # the qcut() function here:\n",
    "    # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "    return pd.qcut(exam_grades,\n",
    "                   [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                   labels=['F', 'D', 'C', 'B', 'A'])\n",
    "\n",
    "# qcut() operates on a list, array, or Series. This is the\n",
    "# result of running the function on a single column of the\n",
    "# DataFrame.\n",
    "print(\"apply() on 1 column of grades_df\\n\",convert_grades_curve(grades_df['exam1']))\n",
    "\n",
    "# qcut() does not work on DataFrames, but we can use apply()\n",
    "# to call the function on each column separately\n",
    "print(\"apply() on all column of grades_df\\n\",grades_df.apply(convert_grades_curve))\n",
    "\n",
    "#case study:\n",
    "'''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "'''\n",
    "\n",
    "def standardize(df):\n",
    "\n",
    "    #print(\"\\n\",df.values.mean(axis=0))\n",
    "    #print(\"\\n\",df.std(axis=0))\n",
    "    return (df-df.mean())/df.std(ddof=0)\n",
    "\n",
    "#pd.DataFrame(grades_df['exam1']).apply(standardize_1)\n",
    "grades_df.apply(standardize)\n",
    "\n",
    "#alternate way to do this\n",
    "#step 1: function that works on single column\n",
    "def standardize_col(my_column):\n",
    "    return (my_column - my_column.mean())/my_column.std()\n",
    "\n",
    "#step 2: apply on whole dataframe\n",
    "def standardize_new(df):\n",
    "    return df.apply(standardize_col)\n",
    "\n",
    "standardize_new(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c\n",
      "0  4  20  25\n",
      "1  5  10  20\n",
      "2  3  40   5\n",
      "3  1  50  15\n",
      "4  2  30  10\n",
      "a     3.0\n",
      "b    30.0\n",
      "c    15.0\n",
      "dtype: float64\n",
      "a     5\n",
      "b    50\n",
      "c    25\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Here apply() used- \n",
    "'''It can also be applied to each COLUMN of a dataframe such that it for each column, \n",
    "it returns a single object, and final returned value is a SERIES'''\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply() - use case 2\n",
    "if 1: \n",
    "    print(df)\n",
    "    print(df.apply(np.mean))\n",
    "    print(df.apply(np.max))\n",
    "    \n",
    "'''\n",
    "Fill in this function to return the second-largest value of each \n",
    "column of the input DataFrame.\n",
    "'''\n",
    "def second_largest(df):\n",
    "    row_count,col_count=np.shape(df)\n",
    "    print(type(df))\n",
    "    my_arr=np.zeros(shape=(col_count))\n",
    "    for i in range(col_count):\n",
    "        max_val=df.iloc[:,i].max()\n",
    "        max_val_posn=np.argmax(df.iloc[:,i])\n",
    "        val=df.iloc[:,i].min()\n",
    "        for j in range(row_count):\n",
    "            if j!=max_val_posn:\n",
    "                if val<df.iloc[j,i] :\n",
    "                    val=df.iloc[j,i]\n",
    "        \n",
    "        my_arr[i]=val\n",
    "        \n",
    "        print(max_val,\" \",max_val_posn)\n",
    "        print(\"2nd largest \",val)\n",
    "           \n",
    "    return pd.DataFrame(my_arr)\n",
    "\n",
    "second_largest(df)\n",
    "\n",
    "#alternate way to find 2nd largest value in DATAFRAME:\n",
    "#step1: write function to find 2nd largest value in COLUMN\n",
    "def second_largest_in_col(my_col):\n",
    "    #first sort in DESCENDING order\n",
    "    sorted_column=my_col.sort_values(ascending=False,inplace=False)\n",
    "    #now largest value will be at posn o and 2nd largest value will be at posn 1\n",
    "    return sorted_column.iloc[1]\n",
    "\n",
    "#second_largest_in_col(df['a'])\n",
    "\n",
    "#step2: apply this above function on whole dataframe\n",
    "def second_largest_2(df):\n",
    "    return df.apply(second_largest_in_col)\n",
    "\n",
    "second_largest_2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding DataFrame to Series : diff cases->\n",
    "in adding a series to a dataframe-\n",
    "This adds each value of Series to one column of the DataFrame\n",
    "Matching in addition is done based on - index of Series with Col name of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case1: Adding a Series to a square DataFrame\n",
    "Here addition is down row wise Vs col wise\n",
    "df.col[i]+series.col[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160 \n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64 \n",
      "\n",
      "    0   1    2    3\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({\n",
    "    0: [10, 20, 30, 40],\n",
    "    1: [50, 60, 70, 80],\n",
    "    2: [90, 100, 110, 120],\n",
    "    3: [130, 140, 150, 160]\n",
    "})\n",
    "\n",
    "print(df,\"\\n\")\n",
    "print(s,\"\\n\")\n",
    "print(df + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case 2: Adding a Series to a one-row DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3\n",
      "0  10  20  30  40 \n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64 \n",
      "\n",
      "    0   1   2   3\n",
      "0  11  22  33  44\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "\n",
    "print(df,\"\\n\")\n",
    "print(s,\"\\n\")\n",
    "print(df + s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case3: Adding a Series to a one-column DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\n",
      "0  10\n",
      "1  20\n",
      "2  30\n",
      "3  40 \n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64 \n",
      "\n",
      "    0   1   2   3\n",
      "0  11 NaN NaN NaN\n",
      "1  21 NaN NaN NaN\n",
      "2  31 NaN NaN NaN\n",
      "3  41 NaN NaN NaN\n",
      "    0   1   2   3\n",
      "0  11 NaN NaN NaN\n",
      "1  21 NaN NaN NaN\n",
      "2  31 NaN NaN NaN\n",
      "3  41 NaN NaN NaN\n",
      "    0\n",
      "0  11\n",
      "1  22\n",
      "2  33\n",
      "3  44\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "print(df,\"\\n\")\n",
    "print(s,\"\\n\")\n",
    "print(df + s)\n",
    "print(df.add(s,axis='columns')) #same as above\n",
    "print(df.add(s,axis='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case 4: Adding when DataFrame column names match Series index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b    c    d\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160 \n",
      "\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64 \n",
      "\n",
      "    a   b    c    d\n",
      "0  11  52   93  134\n",
      "1  21  62  103  144\n",
      "2  31  72  113  154\n",
      "3  41  82  123  164\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "df = pd.DataFrame({\n",
    "    'a': [10, 20, 30, 40],\n",
    "    'b': [50, 60, 70, 80],\n",
    "    'c': [90, 100, 110, 120],\n",
    "    'd': [130, 140, 150, 160]\n",
    "})\n",
    "    \n",
    "print(df,\"\\n\")\n",
    "print(s,\"\\n\")\n",
    "print(df + s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case 5: Adding when DataFrame column names don't match Series index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b    c    d\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160 \n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64 \n",
      "\n",
      "    a   b   c   d   0   1   2   3\n",
      "0 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "1 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "2 NaN NaN NaN NaN NaN NaN NaN NaN\n",
      "3 NaN NaN NaN NaN NaN NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({\n",
    "    'a': [10, 20, 30, 40],\n",
    "    'b': [50, 60, 70, 80],\n",
    "    'c': [90, 100, 110, 120],\n",
    "    'd': [130, 140, 150, 160]\n",
    "})\n",
    "    \n",
    "print(df,\"\\n\")\n",
    "print(s,\"\\n\")\n",
    "print(df + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case study: standardize each col and each row w/o using apply function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2\n",
      "            exam1     exam2\n",
      "Andre   -2.315341 -2.304599\n",
      "Barry    0.220191  0.386400\n",
      "Chris    0.020017 -0.096600\n",
      "Dan     -0.180156 -0.096600\n",
      "Emilio   0.753987  0.662400\n",
      "Fred    -0.513779 -0.441600\n",
      "Greta    0.887436  1.490400\n",
      "Humbert -0.847401 -0.786600\n",
      "Ivan     1.354508  1.007400\n",
      "James    0.620538  0.179400\n",
      "10 2\n",
      "         exam1  exam2\n",
      "Andre      1.0   -1.0\n",
      "Barry      1.0   -1.0\n",
      "Chris      1.0   -1.0\n",
      "Dan        1.0   -1.0\n",
      "Emilio     1.0   -1.0\n",
      "Fred       1.0   -1.0\n",
      "Greta      1.0   -1.0\n",
      "Humbert    1.0   -1.0\n",
      "Ivan       1.0   -1.0\n",
      "James      1.0   -1.0\n"
     ]
    }
   ],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "'''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "\n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "'''\n",
    "\n",
    "def std_cols(df):\n",
    "    x=df.copy()\n",
    "    #print(x)\n",
    "    \n",
    "    row_count,col_count=np.shape(x)\n",
    "    print(row_count,col_count)\n",
    "    \n",
    "    for i in range(col_count):\n",
    "        #print(x.iloc[:,i])\n",
    "        \n",
    "        col_mean=x.iloc[:,i].mean()\n",
    "        col_std=x.iloc[:,i].std(ddof=0)\n",
    "        #print(\"col_mean: \",col_mean) \n",
    "        #print(\"col_std: \",col_std)\n",
    "        for j in range(row_count):\n",
    "            t=x.iloc[j,i]\n",
    "            x.iloc[j,i]=float((t-col_mean)/col_std)\n",
    "               \n",
    "    \n",
    "    return x\n",
    "\n",
    "print(std_cols(grades_df))\n",
    "\n",
    "def std_cols2(df):\n",
    "    x=df.copy()\n",
    "    mean_col=x.mean()\n",
    "    std_col=x.std(ddof=0)\n",
    "    return ((x-mean_col)/std_col)\n",
    "\n",
    "print(std_cols2(grades_df))\n",
    "\n",
    "\n",
    "'''\n",
    "    Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "\n",
    "    This one is more challenging than standardizing each column!\n",
    "'''\n",
    "\n",
    "def std_rows(df):\n",
    "    x=df.copy()\n",
    "    #print(x)\n",
    "    \n",
    "    row_count,col_count=np.shape(x)\n",
    "    print(row_count,col_count)\n",
    "    for i in range(row_count):\n",
    "        #print(x.iloc[:,i])\n",
    "        \n",
    "        col_mean=x.iloc[i,:].mean()\n",
    "        col_std=x.iloc[i,:].std(ddof=0)\n",
    "        #print(\"row_mean: \",col_mean) \n",
    "        #print(\"row_std: \",col_std)\n",
    "        for j in range(col_count):\n",
    "            t=x.iloc[i,j]\n",
    "            #print(t)\n",
    "            x.iloc[i,j]=float((t-col_mean)/col_std)\n",
    "    return x\n",
    "    #return None\n",
    "\n",
    "print(std_rows(grades_df))\n",
    "\n",
    "\n",
    "def std_rows2(df):\n",
    "    x=df.copy()\n",
    "    #to get mean of each row; axis=columns works on ROW, and returns a SERIES\n",
    "    mean_row=x.mean(axis='columns')\n",
    "    #to get std of each column; axis=columns works on ROW, and returns a SERIES\n",
    "    std_row=x.std(axis='columns') \n",
    "    \n",
    "    #to apply Series on columns of DataFrame\n",
    "    #Step1:subtract series from dataframe using sub() function, and axis=index option\n",
    "    mean_diff= x.sub(mean_row,axis='index')\n",
    "    \n",
    "    #Step2: Divide series from dataframe using div() function, and axis=index option\n",
    "    y= mean_diff.div(std_row,axis='index')\n",
    "    \n",
    "    #print(mean_row, type(mean_row))\n",
    "    #print(std_row, type(std_row))\n",
    "    return y \n",
    "    \n",
    "std_rows2(grades_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Group BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   -0.577350\n",
      "b    1.154701\n",
      "c   -1.224745\n",
      "d    0.000000\n",
      "e   -0.577350\n",
      "f    1.224745\n",
      "g    0.000000\n",
      "Name: value, dtype: float64\n",
      "even\n",
      "False    1\n",
      "True     4\n",
      "Name: value, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jai mata di\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:18: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "def standardize(xs):\n",
    "    return (xs - xs.mean()) / xs.std()\n",
    "grouped_data = example_df.groupby('even')\n",
    "print(grouped_data['value'].apply(standardize))\n",
    "    \n",
    "# Find second largest value in each group\n",
    "def second_largest(xs):\n",
    "    sorted_xs = xs.sort(inplace=False, ascending=False)\n",
    "    return sorted_xs.iloc[1]\n",
    "grouped_data = example_df.groupby('even')\n",
    "print(grouped_data['value'].apply(second_largest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn    EXITSn     TIMEn  UNIT\n",
      "0   3144312   1088151  00:00:00  R051\n",
      "1   8936644  13755385  02:00:00  R079\n",
      "2   3144335   1088159  04:00:00  R051\n",
      "3   8936658  13755393  06:00:00  R079\n",
      "4   3144353   1088177  08:00:00  R051\n",
      "5   8936687  13755598  10:00:00  R079\n",
      "6   3144424   1088231  12:00:00  R051\n",
      "7   8936819  13756191  14:00:00  R079\n",
      "8   3144594   1088275  16:00:00  R051\n",
      "    ENTRIESn      EXITSn     TIMEn  UNIT\n",
      "0        NaN         NaN       NaN   NaN\n",
      "1  3144312.0   1088151.0  00:00:00  R051\n",
      "2  8936644.0  13755385.0  02:00:00  R079\n",
      "3  3144335.0   1088159.0  04:00:00  R051\n",
      "4  8936658.0  13755393.0  06:00:00  R079\n",
      "5  3144353.0   1088177.0  08:00:00  R051\n",
      "6  8936687.0  13755598.0  10:00:00  R079\n",
      "7  3144424.0   1088231.0  12:00:00  R051\n",
      "8  8936819.0  13756191.0  14:00:00  R079\n"
     ]
    }
   ],
   "source": [
    "#Group BY Case Study:\n",
    "# DataFrame with cumulative entries and exits for multiple stations\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "\n",
    "print(ridership_df)\n",
    "\n",
    "def get_hourly_for_group(entries_and_exits):\n",
    "    return (entries_and_exits-entries_and_exits.shift(1))\n",
    "\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits and return a DataFrame with hourly entries and exits.\n",
    "    The hourly entries and exits should be calculated separately for\n",
    "    each station (the 'UNIT' column).\n",
    "    \n",
    "    Hint: Use the `get_hourly_entries_and_exits()` function you wrote\n",
    "    in a previous quiz, DataFrame Vectorized Operations, and the `.apply()`\n",
    "    function, to help solve this problem.\n",
    "    '''\n",
    "    x=entries_and_exits.groupby('UNIT')[['ENTRIESn','EXITSn']].apply(get_hourly_for_group).dropna()\n",
    "    return x\n",
    "\n",
    "print(get_hourly_entries_and_exits(ridership_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn  EXITSn\n",
      "2      23.0     8.0\n",
      "3      14.0     8.0\n",
      "4      18.0    18.0\n",
      "5      29.0   205.0\n",
      "6      71.0    54.0\n",
      "7     132.0   593.0\n",
      "8     170.0    44.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
