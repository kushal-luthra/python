{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = ['Albania', 'Algeria', 'Andorra', 'Angola', 'Antigua and Barbuda',\n",
    "             'Argentina', 'Armenia', 'Australia', 'Austria', 'Azerbaijan',\n",
    "             'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus',\n",
    "             'Belgium', 'Belize', 'Benin', 'Bhutan', 'Bolivia']\n",
    "\n",
    "life_expectancy_values = [74.7,  75. ,  83.4,  57.6,  74.6,  75.4,  72.3,  81.5,  80.2,\n",
    "                          70.3,  72.1,  76.4,  68.1,  75.2,  69.8,  79.4,  70.8,  62.7,\n",
    "                          67.3,  70.6]\n",
    "\n",
    "gdp_values = [ 1681.61390973,   2155.48523109,  21495.80508273,    562.98768478,\n",
    "              13495.1274663 ,   9388.68852258,   1424.19056199,  24765.54890176,\n",
    "              27036.48733192,   1945.63754911,  21721.61840978,  13373.21993972,\n",
    "                483.97086804,   9783.98417323,   2253.46411147,  25034.66692293,\n",
    "               3680.91642923,    366.04496652,   1175.92638695,   1132.21387981]\n",
    "\n",
    "# Life expectancy and gdp data in 2007 for 20 countries\n",
    "life_expectancy = pd.Series(life_expectancy_values)\n",
    "gdp = pd.Series(gdp_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.7\n",
      "3      562.987685\n",
      "4    13495.127466\n",
      "5     9388.688523\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements and slicing\n",
    "if 1:\n",
    "    print(life_expectancy[0])\n",
    "    print(gdp[3:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining life expectancy 74.7\n",
      "Examining life expectancy 75.0\n",
      "Examining life expectancy 83.4\n",
      "Examining life expectancy 57.6\n",
      "Examining life expectancy 74.6\n",
      "Examining life expectancy 75.4\n",
      "Examining life expectancy 72.3\n",
      "Examining life expectancy 81.5\n",
      "Examining life expectancy 80.2\n",
      "Examining life expectancy 70.3\n",
      "Examining life expectancy 72.1\n",
      "Examining life expectancy 76.4\n",
      "Examining life expectancy 68.1\n",
      "Examining life expectancy 75.2\n",
      "Examining life expectancy 69.8\n",
      "Examining life expectancy 79.4\n",
      "Examining life expectancy 70.8\n",
      "Examining life expectancy 62.7\n",
      "Examining life expectancy 67.3\n",
      "Examining life expectancy 70.6\n"
     ]
    }
   ],
   "source": [
    "# Looping\n",
    "if 1:\n",
    "    for country_life_expectancy in life_expectancy:\n",
    "        print('Examining life expectancy {}'.format(country_life_expectancy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.86999999999999\n",
      "6.213999474869968\n",
      "27036.4873319\n",
      "182957.59832967003\n"
     ]
    }
   ],
   "source": [
    "# Pandas functions\n",
    "if 1:\n",
    "    print(life_expectancy.mean())\n",
    "    print(life_expectancy.std())\n",
    "    print(gdp.max())\n",
    "    print(gdp.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    4\n",
      "2    4\n",
      "3    6\n",
      "dtype: int64\n",
      "0    2\n",
      "1    4\n",
      "2    6\n",
      "3    8\n",
      "dtype: int64\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "dtype: bool\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations and index arrays\n",
    "if 1:\n",
    "    a = pd.Series([1, 2, 3, 4])\n",
    "    b = pd.Series([1, 2, 1, 2])\n",
    "  \n",
    "    print(a + b)\n",
    "    print(a * 2)\n",
    "    print(a >= 3)\n",
    "    print(a[a >= 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.86999999999999\n",
      "9147.879916483502\n",
      "17\n",
      "3\n",
      "(17, 3)\n"
     ]
    }
   ],
   "source": [
    "def variable_correlation(variable1, variable2):\n",
    "    '''\n",
    "    Fill in this function to calculate the number of data points for which\n",
    "    the directions of variable1 and variable2 relative to the mean are the\n",
    "    same, and the number of data points for which they are different.\n",
    "    Direction here means whether each value is above or below its mean.\n",
    "    \n",
    "    You can classify cases where the value is equal to the mean for one or\n",
    "    both variables however you like.\n",
    "    \n",
    "    Each argument will be a Pandas series.\n",
    "    \n",
    "    For example, if the inputs were pd.Series([1, 2, 3, 4]) and\n",
    "    pd.Series([4, 5, 6, 7]), then the output would be (4, 0).\n",
    "    This is because 1 and 4 are both below their means, 2 and 5 are both\n",
    "    below, 3 and 6 are both above, and 4 and 7 are both above.\n",
    "    \n",
    "    On the other hand, if the inputs were pd.Series([1, 2, 3, 4]) and\n",
    "    pd.Series([7, 6, 5, 4]), then the output would be (0, 4).\n",
    "    This is because 1 is below its mean but 7 is above its mean, and\n",
    "    so on.\n",
    "    '''\n",
    "    num_same_direction = 0        # Replace this with your code\n",
    "    num_different_direction = 0   # Replace this with your code\n",
    "    life_exp_mean=variable1.mean()\n",
    "    gdp_mean=variable2.mean()\n",
    "    print(life_exp_mean)\n",
    "    print(gdp_mean)\n",
    "    \n",
    "    for i in range(len(variable1)):\n",
    "        if variable1[i]>life_exp_mean and variable2[i]>gdp_mean:\n",
    "            num_same_direction+=1\n",
    "        elif variable1[i]<life_exp_mean and variable2[i]<gdp_mean:\n",
    "            num_same_direction+=1\n",
    "        else:\n",
    "            num_different_direction+=1\n",
    "\n",
    "            \n",
    "            \n",
    "    print(num_same_direction)\n",
    "    print(num_different_direction)\n",
    "    return (num_same_direction, num_different_direction)\n",
    "    \n",
    "print(variable_correlation(life_expectancy,gdp))\n",
    "#variable_correlation(life_expectancy,gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 3)\n"
     ]
    }
   ],
   "source": [
    "#alternate way of doing above operations\n",
    "#In python, you can treat Boolean as 1 and 0 for True and False.\n",
    "# So â€“\n",
    "# True + True =2\n",
    "# True + false=1\n",
    "#we use this property below\n",
    "\n",
    "def variable_correlation2(variable1, variable2):\n",
    "    \n",
    "    both_above=(variable1 > variable1.mean()) & (variable2 > variable2.mean())\n",
    "    #print(both_above)\n",
    "    \n",
    "    both_below=(variable1 < variable1.mean()) & (variable2 < variable2.mean())\n",
    "    #print(both_below)\n",
    "    \n",
    "    #create an array \n",
    "    is_same_direction=both_above | both_below\n",
    "    \n",
    "    \n",
    "    num_same_direction=is_same_direction.sum()\n",
    "    num_different_direction=len(variable1)-num_same_direction\n",
    "    \n",
    "    return(num_same_direction,num_different_direction)\n",
    "\n",
    "print(variable_correlation2(life_expectancy,gdp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angola', 75.699996949999999)\n",
      "('Angola', 75.699996949999999)\n"
     ]
    }
   ],
   "source": [
    "#next\n",
    "countries = [\n",
    "    'Afghanistan', 'Albania', 'Algeria', 'Angola', 'Argentina',\n",
    "    'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas',\n",
    "    'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium',\n",
    "    'Belize', 'Benin', 'Bhutan', 'Bolivia',\n",
    "    'Bosnia and Herzegovina'\n",
    "]\n",
    "\n",
    "\n",
    "employment_values = [\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695,\n",
    "    58.40000153,  40.09999847,  61.5       ,  57.09999847,\n",
    "    60.90000153,  66.59999847,  60.40000153,  68.09999847,\n",
    "    66.90000153,  53.40000153,  48.59999847,  56.79999924,\n",
    "    71.59999847,  58.40000153,  70.40000153,  41.20000076\n",
    "]\n",
    "\n",
    "# Employment data in 2007 for 20 countries\n",
    "employment = pd.Series(employment_values, index=countries)\n",
    "\n",
    "def max_employment(employment):\n",
    "    '''\n",
    "    Fill in this function to return the name of the country\n",
    "    with the highest employment in the given employment\n",
    "    data, and the employment in that country.\n",
    "    \n",
    "    The input will be a Pandas series where the values\n",
    "    are employment and the index is country names.\n",
    "    \n",
    "    Try using the Pandas argmax() function. Documention is\n",
    "    here: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.argmax.html\n",
    "    '''\n",
    "    max_country=''      # Replace this with your code\n",
    "    max_value =0   # Replace this with your code\n",
    "    \n",
    "    for i in range(len(employment)):\n",
    "        if max_value<employment.iloc[i]:\n",
    "            max_value=employment.iloc[i]\n",
    "            max_country=employment.index[i]\n",
    "            \n",
    "    #print(\"max_country \",max_country)   \n",
    "    return (max_country, max_value)\n",
    "    \n",
    "print(max_employment(employment))\n",
    "#max_employment(employment)\n",
    "\n",
    "#alternate way to do this\n",
    "def max_employment2(employment):\n",
    "    #argmax function in series returns INDEX with max corresponding value\n",
    "    max_country=employment.argmax()\n",
    "    max_value=employment.loc[max_country]\n",
    "    \n",
    "    return (max_country, max_value)\n",
    "\n",
    "print(max_employment2(employment))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition when indexes are the same: \n",
      " a    11\n",
      "b    22\n",
      "c    33\n",
      "d    44\n",
      "dtype: int64\n",
      "Indexes have same elements in a different order:\n",
      "  a    31\n",
      "b    12\n",
      "c    43\n",
      "d    24\n",
      "dtype: int64\n",
      "Indexes overlap, but do not have exactly the same elements: \n",
      " a     NaN\n",
      "b     NaN\n",
      "c    13.0\n",
      "d    24.0\n",
      "e     NaN\n",
      "f     NaN\n",
      "dtype: float64\n",
      "Indexes do not overlap:\n",
      "  a   NaN\n",
      "b   NaN\n",
      "c   NaN\n",
      "d   NaN\n",
      "e   NaN\n",
      "f   NaN\n",
      "g   NaN\n",
      "h   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#vectorized series operations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Addition when indexes are the same\n",
    "if 1:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "    print(\"Addition when indexes are the same: \\n\",s1 + s2)\n",
    "\n",
    "# Indexes have same elements in a different order\n",
    "if 1:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['b', 'd', 'a', 'c'])\n",
    "    print(\"Indexes have same elements in a different order:\\n \",s1 + s2)\n",
    "\n",
    "# Indexes overlap, but do not have exactly the same elements\n",
    "if 1:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['c', 'd', 'e', 'f'])\n",
    "    print(\"Indexes overlap, but do not have exactly the same elements: \\n\",s1 + s2)\n",
    "\n",
    "# Indexes do not overlap\n",
    "if 1:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['e', 'f', 'g', 'h'])\n",
    "    print(\"Indexes do not overlap:\\n \",s1 + s2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#we can pass our own function to series using apply() function.\n",
    "#apply() applies function to each value of series \n",
    "def print_len_series_(myseries):\n",
    "    print(len(myseries))\n",
    "\n",
    "s=pd.Series(['a','aa','aaa'])\n",
    "#print(s)\n",
    "s.apply(print_len_series_); #note: we havent passed parenthesis to our internal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Agassi, Andre\n",
      "1              Bonds, Barry\n",
      "2     Columbus, Christopher\n",
      "3             Defoe, Daniel\n",
      "4           Estevez, Emilio\n",
      "5          Flintstone, Fred\n",
      "6              Garbo, Greta\n",
      "7          Humbert, Humbert\n",
      "8               Ilych, Ivan\n",
      "9              Joyce, James\n",
      "10         Knightley, Keira\n",
      "11               Lane, Lois\n",
      "12              Myers, Mike\n",
      "13              Nolte, Nick\n",
      "14           Osbourne, Ozzy\n",
      "15           Picasso, Pablo\n",
      "16       Quirrell, Quirinus\n",
      "17             Ray, Rachael\n",
      "18          Sarandon, Susan\n",
      "19             Turner, Tina\n",
      "20           Urbina, Ugueth\n",
      "21            Vaughn, Vince\n",
      "22          Wilson, Woodrow\n",
      "23             Yamada, Yoji\n",
      "24         Zidane, Zinedine\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#case: to reverse a series: lastname firstname\n",
    "names = pd.Series([\n",
    "    'Andre Agassi',\n",
    "    'Barry Bonds',\n",
    "    'Christopher Columbus',\n",
    "    'Daniel Defoe',\n",
    "    'Emilio Estevez',\n",
    "    'Fred Flintstone',\n",
    "    'Greta Garbo',\n",
    "    'Humbert Humbert',\n",
    "    'Ivan Ilych',\n",
    "    'James Joyce',\n",
    "    'Keira Knightley',\n",
    "    'Lois Lane',\n",
    "    'Mike Myers',\n",
    "    'Nick Nolte',\n",
    "    'Ozzy Osbourne',\n",
    "    'Pablo Picasso',\n",
    "    'Quirinus Quirrell',\n",
    "    'Rachael Ray',\n",
    "    'Susan Sarandon',\n",
    "    'Tina Turner',\n",
    "    'Ugueth Urbina',\n",
    "    'Vince Vaughn',\n",
    "    'Woodrow Wilson',\n",
    "    'Yoji Yamada',\n",
    "    'Zinedine Zidane'\n",
    "])\n",
    "\n",
    "def reverse_names(names):\n",
    "    '''\n",
    "    Fill in this function to return a new series where each name\n",
    "    in the input series has been transformed from the format\n",
    "    \"Firstname Lastname\" to \"Lastname, FirstName\".\n",
    "    \n",
    "    Try to use the Pandas apply() function rather than a loop.\n",
    "    '''\n",
    "    y=[]\n",
    "    for i in range(len(names)):\n",
    "        x=names[i].split()\n",
    "        x.reverse()\n",
    "        z=' '.join(x)\n",
    "        y.append(z)\n",
    "        \n",
    "    return pd.Series(y)\n",
    "\n",
    "#print(reverse_names(names))\n",
    "\n",
    "\n",
    "#alternate way to do this\n",
    "def reverse_names2(names):\n",
    "    split_name=names.split(' ')\n",
    "    first_name=split_name[0]\n",
    "    last_name=split_name[1]\n",
    "    return last_name + \", \" + first_name\n",
    "\n",
    "#if applied on single value\n",
    "reverse_names2(names.iloc[0])\n",
    "\n",
    "#when applied to whole pandas series\n",
    "print(names.apply(reverse_names2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'/datasets/ud170/gapminder/employment_above_15.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-d8ebd4563bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/datasets/ud170/gapminder/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0memployment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'employment_above_15.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mfemale_completion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'female_completion_rate.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmale_completion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'male_completion_rate.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jai mata di\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jai mata di\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jai mata di\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jai mata di\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jai mata di\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'/datasets/ud170/gapminder/employment_above_15.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#plotting in pandas\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The following code reads all the Gapminder data into Pandas DataFrames. You'll\n",
    "# learn about DataFrames next lesson.\n",
    "\n",
    "path ='/datasets/ud170/gapminder/'\n",
    "employment = pd.read_csv(path + 'employment_above_15.csv', index_col='Country')\n",
    "female_completion = pd.read_csv(path + 'female_completion_rate.csv', index_col='Country')\n",
    "male_completion = pd.read_csv(path + 'male_completion_rate.csv', index_col='Country')\n",
    "life_expectancy = pd.read_csv(path + 'life_expectancy.csv', index_col='Country')\n",
    "gdp = pd.read_csv(path + 'gdp_per_capita.csv', index_col='Country')\n",
    "\n",
    "# The following code creates a Pandas Series for each variable for the United States.\n",
    "# You can change the string 'United States' to a country of your choice.\n",
    "\n",
    "employment_us = employment.loc['United States']\n",
    "female_completion_us = female_completion.loc['United States']\n",
    "male_completion_us = male_completion.loc['United States']\n",
    "life_expectancy_us = life_expectancy.loc['United States']\n",
    "gdp_us = gdp.loc['United States']\n",
    "\n",
    "# Uncomment the following line of code to see the available country names\n",
    "#print(employment.index.values)\n",
    "\n",
    "# Use the Series defined above to create a plot of each variable over time for\n",
    "# the country of your choice. You will only be able to display one plot at a time\n",
    "# with each \"Test Run\".\n",
    "def plot_data(val,pl):\n",
    "    print(employment.index[val])\n",
    "    if pl==1: \n",
    "        print(\"employment Vs year\")\n",
    "        employment.iloc[val].plot()\n",
    "    if pl==2: \n",
    "        print(\"female_completion Vs year\")\n",
    "        female_completion.iloc[val].plot()\n",
    "    if pl==3: \n",
    "        print(\"male_completion Vs year\")\n",
    "        male_completion.iloc[val].plot()\n",
    "    if pl==4: \n",
    "        print(\"life_expectancy Vs year\")\n",
    "        life_expectancy.iloc[val].plot()\n",
    "    if pl==5: \n",
    "        print(\"gdp Vs year\")\n",
    "        gdp.iloc[val].plot()\n",
    "    plt.show()\n",
    "\n",
    "plot_data(21,3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
